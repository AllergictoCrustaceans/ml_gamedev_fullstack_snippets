{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b883560",
   "metadata": {},
   "source": [
    "# DCGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d32551f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.31.0-py3-none-any.whl (313 kB)\n",
      "                                              0.0/313.2 kB ? eta -:--:--\n",
      "     ---                                   30.7/313.2 kB 445.2 kB/s eta 0:00:01\n",
      "     -------                               61.4/313.2 kB 550.5 kB/s eta 0:00:01\n",
      "     ------------------------               204.8/313.2 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 313.2/313.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from imageio) (1.23.5)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from imageio) (9.5.0)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.31.0\n",
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\katie\\appdata\\local\\temp\\pip-req-build-bx1ueh6_\n",
      "  Resolved https://github.com/tensorflow/docs to commit e24446b758940871677d6a40cd1fa0f4724194da\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting astor (from tensorflow-docs==2023.5.26.9808)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from tensorflow-docs==2023.5.26.9808) (1.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from tensorflow-docs==2023.5.26.9808) (3.1.2)\n",
      "Requirement already satisfied: nbformat in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from tensorflow-docs==2023.5.26.9808) (5.8.0)\n",
      "Requirement already satisfied: protobuf>=3.12 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from tensorflow-docs==2023.5.26.9808) (4.23.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from tensorflow-docs==2023.5.26.9808) (6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from jinja2->tensorflow-docs==2023.5.26.9808) (2.1.2)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (2.16.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (4.17.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (5.3.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from nbformat->tensorflow-docs==2023.5.26.9808) (5.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.5.26.9808) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from jsonschema>=2.6->nbformat->tensorflow-docs==2023.5.26.9808) (0.19.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2023.5.26.9808) (3.5.1)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\katie\\anaconda3\\envs\\ml_basics\\lib\\site-packages (from jupyter-core->nbformat->tensorflow-docs==2023.5.26.9808) (304)\n",
      "Building wheels for collected packages: tensorflow-docs\n",
      "  Building wheel for tensorflow-docs (setup.py): started\n",
      "  Building wheel for tensorflow-docs (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorflow-docs: filename=tensorflow_docs-2023.5.26.9808-py3-none-any.whl size=185058 sha256=3e07b3276359479fbbf53288812fcdef273a9279b70e04680cdf66450a0e1078\n",
      "  Stored in directory: C:\\Users\\katie\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-mcb40yss\\wheels\\86\\0f\\1e\\3b62293c8ffd0fd5a49508e6871cdb7554abe9c62afd35ec53\n",
      "Successfully built tensorflow-docs\n",
      "Installing collected packages: astor, tensorflow-docs\n",
      "Successfully installed astor-0.8.1 tensorflow-docs-2023.5.26.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\katie\\AppData\\Local\\Temp\\pip-req-build-bx1ueh6_'\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio\n",
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ccd0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f49041",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cdba46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55842c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "train_images = (train_images - 127.5) / 127.5 # normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f32845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb83fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48799f15",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd75c3",
   "metadata": {},
   "source": [
    "### Build Generator\n",
    "\n",
    "The generator uses `tf.keras.layer.Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). \n",
    "- Start with a `Dense` layer that takes this seed as an input\n",
    "- Upsample several times until you reach the desired image size of `28 x 28 x 1`\n",
    "- `tf.keras.layers.LeakyReLU` action in each layer, except the output layer which uses `tanh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5f40955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False, activation=\"tanh\"))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e23901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1bab3221d80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55114415",
   "metadata": {},
   "source": [
    "### Create Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668ed840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1]))\n",
    "    \n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f5ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00190743]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision =  discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f2c2c",
   "metadata": {},
   "source": [
    "### Define the Loss and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ee1fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab9e95d",
   "metadata": {},
   "source": [
    "### Discriminator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ea298f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871ac1d",
   "metadata": {},
   "source": [
    "### Generator Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ccdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875b27a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b616f",
   "metadata": {},
   "source": [
    "### Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db21be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                discriminator_optimizer=discriminator_optimizer,\n",
    "                                generator=generator,\n",
    "                                discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202b29c0",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3508f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# you will reuse this seed overtime (so it's easier) to visualize progress in the animated GIF\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75bdb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss,\n",
    "                                              generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss,\n",
    "                                                   discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05f09b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "        \n",
    "        # produce images for the GIF as you go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        # save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "        \n",
    "        print(f\"Time for epoch {epoch + 1} is {time.time() - start} sec.\")\n",
    "        \n",
    "    # generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f74c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "    plt.savefig(f\"image_at_epoch_{epoch}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9899d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cc661",
   "metadata": {},
   "source": [
    "## Create a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open(f\"image_at_epoch_{epoch_no}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faa3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c11b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = \"dcgan.gif\"\n",
    "\n",
    "with imageio.get_writer(anim_file, mode=\"I\") as writer:\n",
    "    filenames = glob.glob(\"image*.png\")\n",
    "    filenames = sorted(filenames)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab16719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
